{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d476a2-8513-4b37-90bf-aadbf073fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpimux6z2m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpimux6z2m/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpimux6z2m'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13272097104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272098640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272098448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272099408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272099216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272100176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272098064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272101712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272101136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13272102672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743066853.934661 3989299 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion successful! Model saved as Flower_classification.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743066853.935563 3989299 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-03-27 14:59:13.937392: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpimux6z2m\n",
      "2025-03-27 14:59:13.937866: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-03-27 14:59:13.937871: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpimux6z2m\n",
      "2025-03-27 14:59:13.944842: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-03-27 14:59:14.026358: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpimux6z2m\n",
      "2025-03-27 14:59:14.035688: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 98296 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load your Keras model\n",
    "model = tf.keras.models.load_model('Flower_recognition.h5')\n",
    "\n",
    "# Convert to TFLite with proper settings\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# These settings ensure compatibility\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "converter.experimental_new_converter = True\n",
    "\n",
    "# Convert and save\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('Flower_classification.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Conversion successful! Model saved as Flower_classification.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe87b0dc-56e5-44c8-8c59-9421dadd4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details: [{'name': 'serving_default_input_layer_1:0', 'index': 0, 'shape': array([  1, 180, 180,   3], dtype=int32), 'shape_signature': array([ -1, 180, 180,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Flower_classification.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "print(\"Input Details:\", input_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653efc90-f5db-4a6b-a734-1178777ef3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"Flower_classification.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def classify_tflite(image_path):\n",
    "    input_image = tf.keras.utils.load_img(image_path, target_size=(180,180))\n",
    "    input_image_array = tf.keras.utils.img_to_array(input_image)\n",
    "    input_image_array = np.expand_dims(input_image_array, axis=0) / 255.0  # Normalize\n",
    "\n",
    "    # Set input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_image_array.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get output tensor\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    result = tf.nn.softmax(output_data[0])  # Apply softmax\n",
    "\n",
    "    outcome = f\"The image belongs to {flower_names[np.argmax(result)]} with a score of {np.max(result) * 100:.2f}%\"\n",
    "    return outcome\n",
    "\n",
    "print(classify_tflite(\"upload/rose.jpg\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
