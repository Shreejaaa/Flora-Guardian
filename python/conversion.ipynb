{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129b1285-fb38-4ff1-b140-18f16dd9e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmp6ui0320m/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmp6ui0320m/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmp6ui0320m'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  6319849744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319853776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319853200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319854736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319854160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319855696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319855888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319857616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319856656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6319858768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ TFLite model saved successfully as 'flower_recognition.tflite'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1742978151.072976 3318968 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1742978151.073849 3318968 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-03-26 14:20:51.075431: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmp6ui0320m\n",
      "2025-03-26 14:20:51.076061: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-03-26 14:20:51.076066: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmp6ui0320m\n",
      "2025-03-26 14:20:51.082934: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-03-26 14:20:51.154786: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmp6ui0320m\n",
      "2025-03-26 14:20:51.162220: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 86789 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained .h5 model\n",
    "model = tf.keras.models.load_model('Flower_recognition.h5')\n",
    "\n",
    "# Convert to TFLite format with optimizations\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Reduce size, improve performance\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('flower_recognition.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✅ TFLite model saved successfully as 'flower_recognition.tflite'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dccec4ba-8e64-4064-bb44-0f35b780b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details: [{'name': 'serving_default_input_layer_1:0', 'index': 0, 'shape': array([  1, 180, 180,   3], dtype=int32), 'shape_signature': array([ -1, 180, 180,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output Details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 20, 'shape': array([1, 5], dtype=int32), 'shape_signature': array([-1,  5], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Model Output: [[ 1.7023727  2.5639346 -4.711603  -0.7942267 -0.7717607]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"flower_recognition.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"Input Details: {input_details}\")\n",
    "print(f\"Output Details: {output_details}\")\n",
    "\n",
    "# Create a dummy input image (180x180x3) with random values (normalized)\n",
    "input_shape = input_details[0]['shape']\n",
    "dummy_input = np.random.rand(*input_shape).astype(np.float32)\n",
    "\n",
    "# Run inference\n",
    "interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"Model Output: {output_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffa166c-b32d-4dac-b5d5-417f7f4e2d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Flower: dandelion\n",
      "Confidence: 2.5639346\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Model output (logits)\n",
    "logits = np.array([1.7023727, 2.5639346, -4.711603, -0.7942267, -0.7717607])\n",
    "\n",
    "# Flower names corresponding to the logits\n",
    "flower_names = ['daisy', 'dandelion', 'iris', 'rose', 'sunflower']\n",
    "\n",
    "# Get the index of the highest logit\n",
    "predicted_index = np.argmax(logits)\n",
    "\n",
    "# Get the predicted flower name\n",
    "predicted_flower = flower_names[predicted_index]\n",
    "\n",
    "# Get the confidence (value of the highest logit)\n",
    "confidence = logits[predicted_index]\n",
    "\n",
    "print(f\"Predicted Flower: {predicted_flower}\")\n",
    "print(f\"Confidence: {confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2d7791-0556-49f4-b5e6-08425c9f6770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpb18lrwyf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpb18lrwyf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpb18lrwyf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 19), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  6069447440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069448208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069448784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069450128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069449936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069447248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069451472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069452432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074598224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074598608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6069451664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074597456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074598992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074601104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074601296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074601872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074600336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074600528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074598416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074604368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074606672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074607248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074606288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074605712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074612048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6074613392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075583952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075584528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075583568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075582992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075582800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075586448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1742629867.133415  368130 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1742629867.134061  368130 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-03-22 13:36:07.134962: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpb18lrwyf\n",
      "2025-03-22 13:36:07.135842: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-03-22 13:36:07.135846: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpb18lrwyf\n",
      "I0000 00:00:1742629867.143892  368130 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2025-03-22 13:36:07.145224: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-03-22 13:36:07.281446: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/x1/lkxlqzsn619fk3ylr3hzgb0w0000gn/T/tmpb18lrwyf\n",
      "2025-03-22 13:36:07.294396: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 159435 microseconds.\n",
      "2025-03-22 13:36:07.326349: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the .h5 model\n",
    "model = tf.keras.models.load_model('plant_disease_model.h5')\n",
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the .tflite model\n",
    "with open('plant_disease_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e80415-9b55-4a7d-9850-9c1eebf47dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
